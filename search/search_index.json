{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cookiecutter Dash docset A cookiecutter template for automating the generation of documentation sets for use in Dash compatible API browsers using doc2dash and contributing to Kapeli/Dash-User-Contributions . What is this project? Dash is an app 1 that lets you instantly search through documentation sets offline. Hynek Schlawack has a great writeup on the benefits of using Dash. If you find yourself with dozen of documentation tabs open or repeatedly searching for the same APIs, Dash might be useful for you. Dash comes with a few documentation sets, but if a library isn't included you can always generate your own . 2 You can contribute your documentation sets to Kapeli/Dash-User-Contributions to make them available to others. However, if you want to keep things up to date, each time new version of a library releases you need to: Clone the library Reinstall the dependencies Rebuild the docs Convert the docs to a Dash-compatible documentation set Create a pull request for Kapeli/Dash-User-Contributions This is tedious. As a result, many documentation sets don't keep up with their library's release. Cookiecutter Dash docset generates a repository that automates this process. After generating the project and modifying the template in a couple of key areas , you should have a repository that specifies the entire docset building process and automatically re-runs it on GitHub Actions with a new release of the library. Project features Upon detecting a new project release, this project should automatically: Build a new Dash documentation set Contribute the docset to [Kaplei/Dash-User-Contributions] There are multiple alternatives as well\u2014like Zeal , Velocity , Helm Dash , and dasht \u21a9 Tools like doc2dash help automate some of the generation. \u21a9","title":"Home"},{"location":"#cookiecutter-dash-docset","text":"A cookiecutter template for automating the generation of documentation sets for use in Dash compatible API browsers using doc2dash and contributing to Kapeli/Dash-User-Contributions .","title":"Cookiecutter Dash docset"},{"location":"#what-is-this-project","text":"Dash is an app 1 that lets you instantly search through documentation sets offline. Hynek Schlawack has a great writeup on the benefits of using Dash. If you find yourself with dozen of documentation tabs open or repeatedly searching for the same APIs, Dash might be useful for you. Dash comes with a few documentation sets, but if a library isn't included you can always generate your own . 2 You can contribute your documentation sets to Kapeli/Dash-User-Contributions to make them available to others. However, if you want to keep things up to date, each time new version of a library releases you need to: Clone the library Reinstall the dependencies Rebuild the docs Convert the docs to a Dash-compatible documentation set Create a pull request for Kapeli/Dash-User-Contributions This is tedious. As a result, many documentation sets don't keep up with their library's release. Cookiecutter Dash docset generates a repository that automates this process. After generating the project and modifying the template in a couple of key areas , you should have a repository that specifies the entire docset building process and automatically re-runs it on GitHub Actions with a new release of the library.","title":"What is this project?"},{"location":"#project-features","text":"Upon detecting a new project release, this project should automatically: Build a new Dash documentation set Contribute the docset to [Kaplei/Dash-User-Contributions] There are multiple alternatives as well\u2014like Zeal , Velocity , Helm Dash , and dasht \u21a9 Tools like doc2dash help automate some of the generation. \u21a9","title":"Project features"},{"location":"advanced_github_actions_features/","text":"Advanced GitHub actions features Debugging GitHub action runs GitHub actions can be tricky to debug when documentation fails to build, which is why cookiecutter dash docset includes mxschmitt/action-tmate . The action will print out a command that allows you to ssh into the action environment so that you can debug failed runs. How do I trigger a GitHub Actions workflow dispatch? Go to the Actions section of your repository. Select the Build docs workflow. Select Run workflow . Fill in the variables needed and click Run workflow to launch the new run. If we want to launch the tmate debugging session\u2014 we can fill in true under Run the build with tmate debugging enabled . By default, a debugging session will run if Build docs is triggered on a workflow dispatch, Run the build with tmate debugging enabled is set to true , and a failure occurs in the actions steps. Manually triggering a documentation build A new version release of the documentation's library signals to this project that the docset is new and should be contributed to Kapeli/Dash-User-Contributions . You can also trigger this event manually. Similarly to Debugging GitHub action runs , launching an action via workflow dispatch with Manually trigger doc build and release. set to true will force the contribution steps to run regardless of whether the library version has changed. This is useful for when you initially create your repository and want to immediately contribute a new docset without having to wait for a new release.","title":"Advanced GitHub actions features"},{"location":"advanced_github_actions_features/#advanced-github-actions-features","text":"","title":"Advanced GitHub actions features"},{"location":"advanced_github_actions_features/#debugging-github-action-runs","text":"GitHub actions can be tricky to debug when documentation fails to build, which is why cookiecutter dash docset includes mxschmitt/action-tmate . The action will print out a command that allows you to ssh into the action environment so that you can debug failed runs. How do I trigger a GitHub Actions workflow dispatch? Go to the Actions section of your repository. Select the Build docs workflow. Select Run workflow . Fill in the variables needed and click Run workflow to launch the new run. If we want to launch the tmate debugging session\u2014 we can fill in true under Run the build with tmate debugging enabled . By default, a debugging session will run if Build docs is triggered on a workflow dispatch, Run the build with tmate debugging enabled is set to true , and a failure occurs in the actions steps.","title":"Debugging GitHub action runs"},{"location":"advanced_github_actions_features/#manually-triggering-a-documentation-build","text":"A new version release of the documentation's library signals to this project that the docset is new and should be contributed to Kapeli/Dash-User-Contributions . You can also trigger this event manually. Similarly to Debugging GitHub action runs , launching an action via workflow dispatch with Manually trigger doc build and release. set to true will force the contribution steps to run regardless of whether the library version has changed. This is useful for when you initially create your repository and want to immediately contribute a new docset without having to wait for a new release.","title":"Manually triggering a documentation build"},{"location":"code_quality_tools/","text":"Code quality tools The generated project has some code quality tools set up: flake8 for linting Black for autoformatting Mypy for type checking. Both flake8 and black are ran via pre-commit . If you have pre-commit installed, run % pre-commit install in the repository to install flake8 and black as pre-commit hooks. Every time you try to make a commit, the two will be ran to check your code. If [nox] is installed, run nox --session=check-types to check types using Mypy . All checks are enforced via GitHub actions on commits and pull requests. Disabling Not interested in using these linters? Delete .github/workflows/lint.yml and you'll disable the GitHub actions code quality check runs.","title":"Code quality tools"},{"location":"code_quality_tools/#code-quality-tools","text":"The generated project has some code quality tools set up: flake8 for linting Black for autoformatting Mypy for type checking. Both flake8 and black are ran via pre-commit . If you have pre-commit installed, run % pre-commit install in the repository to install flake8 and black as pre-commit hooks. Every time you try to make a commit, the two will be ran to check your code. If [nox] is installed, run nox --session=check-types to check types using Mypy . All checks are enforced via GitHub actions on commits and pull requests.","title":"Code quality tools"},{"location":"code_quality_tools/#disabling","text":"Not interested in using these linters? Delete .github/workflows/lint.yml and you'll disable the GitHub actions code quality check runs.","title":"Disabling"},{"location":"generating_a_project/","text":"Generating a project Cookiecutter must be installed in order to generate this project. How to install cookiecutter You can install cookiecutter using homebrew % brew install cookiecutter or pipx % pipx install cookiecutter Cookiecutter's documents some more detailed installation instructions. Once cookiecutter is installed, run: % cookiecutter https://github.com/paw-lu/cookiecutter-dash-docset You'll get some prompts asking you questions about the generated project: Variable Description Example library_name The name of the library you will generate a docset for. pip library_repository_name The name of the repository on GitHub for the library. By default set equal to library_name . pip repo_releases How the repository records releases. Does it specifically specify releases, or does it just have tagged commits? Has releases installable_name The name of the installable for the library. The thing you would type in when you pip install . By default set to library_repository_name . pip library_version The version of the library to build the docs from. 22.3 library_owner The GitHub owner name of the repository for the library. pypa github_username Your GitHub username. paw-lu your_name Your name. Paulo S. Costa project_name The name of the generated project. By default {library_repository_name}-dash-docset pip-dash-docset documentation_url The url the library's documentation is hosted at. https://pip.pypa.io/en/stable/ python_version The python version which will run the build script. 3.10","title":"Generating a project"},{"location":"generating_a_project/#generating-a-project","text":"Cookiecutter must be installed in order to generate this project. How to install cookiecutter You can install cookiecutter using homebrew % brew install cookiecutter or pipx % pipx install cookiecutter Cookiecutter's documents some more detailed installation instructions. Once cookiecutter is installed, run: % cookiecutter https://github.com/paw-lu/cookiecutter-dash-docset You'll get some prompts asking you questions about the generated project: Variable Description Example library_name The name of the library you will generate a docset for. pip library_repository_name The name of the repository on GitHub for the library. By default set equal to library_name . pip repo_releases How the repository records releases. Does it specifically specify releases, or does it just have tagged commits? Has releases installable_name The name of the installable for the library. The thing you would type in when you pip install . By default set to library_repository_name . pip library_version The version of the library to build the docs from. 22.3 library_owner The GitHub owner name of the repository for the library. pypa github_username Your GitHub username. paw-lu your_name Your name. Paulo S. Costa project_name The name of the generated project. By default {library_repository_name}-dash-docset pip-dash-docset documentation_url The url the library's documentation is hosted at. https://pip.pypa.io/en/stable/ python_version The python version which will run the build script. 3.10","title":"Generating a project"},{"location":"how_it_works/","text":"How it works Cookiecutter Dash documentation sets automates building a library's documentation sets and uploading it to the user contribution repository each time a new version of the library releases. graph TD; library(Library); dependabot(Dependabot); subgraph cookiecutter-dash-docset doc-requirements(<pre>doc-requirements.txt</pre>); tag(New repo tag); repo(Library repository); documentation(Library documentation); docset(Library docset); end dash_repo(Kapeli/Dash-User-Contributions); library -- New release --> dependabot; dependabot -- PR --> doc-requirements; doc-requirements -- Compare to repo tag --> tag; tag -- Clone latest release --> repo; repo -- Run doc build steps --> documentation; documentation -- Run doc2dash --> docset; docset -- Create pull request --> dash_repo; classDef default fill:#EADDFF,stroke:#EADDFF,color:#21005D; classDef label fill:none,stroke:none; classDef edgeLabel fill:none,stroke:none; classDef transparent fill:none,stroke:#625B71; class cookiecutter-dash-docset transparent; This template sets up the following chain of triggers: A new version of the library is released Dependabot create a pull request against the repository, which will trigger a build check on GitHub Actions to verify that the docs correctly build. The pull request will modify the library version in ./doc-requirements.txt . This version will be compared against the current repository tag to verify that it has changed. If the version has changed, the commit is tagged with the newer version. A new tagged commit triggers the newest release of the library to be cloned. After cloning, the doc build steps are ran. doc2dash is ran against the build documentation to create the documentation set A pull request is generated for Kapeli/Dash-User-Contributions with the new documentation set.","title":"How it works"},{"location":"how_it_works/#how-it-works","text":"Cookiecutter Dash documentation sets automates building a library's documentation sets and uploading it to the user contribution repository each time a new version of the library releases. graph TD; library(Library); dependabot(Dependabot); subgraph cookiecutter-dash-docset doc-requirements(<pre>doc-requirements.txt</pre>); tag(New repo tag); repo(Library repository); documentation(Library documentation); docset(Library docset); end dash_repo(Kapeli/Dash-User-Contributions); library -- New release --> dependabot; dependabot -- PR --> doc-requirements; doc-requirements -- Compare to repo tag --> tag; tag -- Clone latest release --> repo; repo -- Run doc build steps --> documentation; documentation -- Run doc2dash --> docset; docset -- Create pull request --> dash_repo; classDef default fill:#EADDFF,stroke:#EADDFF,color:#21005D; classDef label fill:none,stroke:none; classDef edgeLabel fill:none,stroke:none; classDef transparent fill:none,stroke:#625B71; class cookiecutter-dash-docset transparent; This template sets up the following chain of triggers: A new version of the library is released Dependabot create a pull request against the repository, which will trigger a build check on GitHub Actions to verify that the docs correctly build. The pull request will modify the library version in ./doc-requirements.txt . This version will be compared against the current repository tag to verify that it has changed. If the version has changed, the commit is tagged with the newer version. A new tagged commit triggers the newest release of the library to be cloned. After cloning, the doc build steps are ran. doc2dash is ran against the build documentation to create the documentation set A pull request is generated for Kapeli/Dash-User-Contributions with the new documentation set.","title":"How it works"},{"location":"modifying_the_project/","text":"Modifying the project Modifying the template's noxfile.py What's a noxfile and what's nox ? nox is a command line tool for automating the building of environments and running actions. Cookiecutter dash docset uses it to install the dependencies needed to build the documentation and run the build commands. There are 2\u20133 methods you will use: Session.install runs pip commands in the environment created by nox . So if creating your doc-building environment requires you to run: % pip install . % pip install --requirement = docs/requirements.txt This would translate to: session . install ( \".\" ) session . install ( \"--requirement=docs/requirements.txt\" ) Session.chdir Changes the current working directory. Session.run Runs a command in the environment created by nox . If building your docs requires you to run: % cd docs % make html We'll use Session.chdir to translate this to: with session . chdir ( \"docs\" ): session . run ( \"make\" , \"html\" ) A few modifications will need to be made to the template in ./noxfile.py . First, specify the build steps for the library's documentation by modifying docs . Warning All of the functions you need to modify in noxfile.py \u2014 docs , icon , and dash \u2014are set to raise NotImplimented errors as a reminder to the user to make some changes. This will cause nox to fail by default. Remove them once you have completed your changes. ./noxfile.py @nox . session ( python = PYTHON , tags = [ \"build\" ]) def docs ( session : Session ) -> None : \"\"\"Build {{ cookiecutter.library_name }}'s docs.\"\"\" # Remove the NotImplemented error once the correct doc build steps # have been added raise NotImplementedError ( \"Replace starter code below with correct docs build steps.\" ) { #- (1) #} # Instructions are usually found in a file named CONTRIBUTING.md, # or by copying the steps in the workflows found in # .github/workflows/ # Check if it works by running nox --tags=build in your terminal # This is an example doc step process that works with most libraries # It may or may not work with the library you are targeting with session . chdir ( LIBRARY_REPOSITORY ): session . install ( \".\" ) { #- (2) #} with session . chdir ( pathlib . Path ( LIBRARY_REPOSITORY ) / \"docs\" ): session . install ( \"--requirement=requirements.txt\" ) { #- (3) #} session . run ( \"make\" , \"docs\" , external = True ) { #- (4) #} This line is here to make sure you modify the code below to build the docs for your specific library. Remove it after you're done. Here you typically install the package locally Here you install the extra requirements needed to build the docs themselves\u2014maybe sphinx, mkdocs, etc Finally you run the command that builds the docs Second, specify the correct path to an icon relative to the library's repository root. ./noxfile.py @nox . session ( python = False , tags = [ \"build\" ]) def icon ( session : Session ) -> None : \"\"\"Create dash icon.\"\"\" for size , file_name in (( \"16x16\" , \"icon.png\" ), ( \"32x32\" , \"icon@2x.png\" )): # Using convert instead of magick since only the former is # available by default right now in ubuntu-latest # Remove the NotImplementedError once the correct icon path has # been added { #- (1) #} raise NotImplementedError ( \"Specify the correct path to the icon\" ) session . run ( \"convert\" , # Specify the correct path in the line below \"{{ cookiecutter.library_repository_name }}/path/to/icon.png\" , { #- (2) #} \"-resize\" , size , \"-background\" , \"none\" , \"-gravity\" , \"center\" , \"-extent\" , size , file_name , external = True , ) This line is here to make sure you modify the path below to point to the icon for your library. Remove it after you're done. Replace this line with a path pointing towards an image that can be used as the icon for your documentation. The path should start from the name of the directory containing the repository. When you generate the project using [cookiecutter], {{ cookiecutter.library_repository_name }} will automatically be replaced by the repository directory name. Third, specify the correct path to the build documentation. Most Python libraries will build to library_name/doc/_build/html or library_name/docs/_build/html , so not much\u2014if anything\u2014will need to be changed. But there are some exceptions. If you're not sure where the build documentation will be located, run: % nox --sessions clone docs See Running the project locally for more information on how to run this project on your machine. ./noxfile.py @nox . session ( python = PYTHON , tags = [ \"build\" ]) def dash ( session : Session ) -> None : \"\"\"Create dash docset.\"\"\" session . install ( \"doc2dash\" , CONSTRAINTS_ARG ) # Remove the NotImplementedError once the correct path to the build # documentation has been added { #- (1) #} raise NotImplementedError ( \"Specity the correct path to the build documentation\" ) session . run ( \"doc2dash\" , \"--index-page=index.html\" , \"--icon=icon.png\" , \"--online-redirect-url={{ cookiecutter.documentation_url }}\" , # Replace the path below with the correct path to the # documentation # For python libraries, most of the time the below will work as # is # You may run `nox --sessions clone docs` to observe where the # build docs end up f \" { LIBRARY_REPOSITORY } /docs/_build/html\" , { #- (2) #} * session . posargs , ) # As of 3.0.0, doc2dash does not support 2x icons # See https://github.com/hynek/doc2dash/issues/130 docset_path = _get_docset_path () shutil . copy ( \"icon@2x.png\" , os . fsdecode ( docset_path )) The NotImplimentedError line is here to make sure you modify the path below. Remove it after you're done. If necessary, replace this with the path to the build documentation. The placeholder value will work for most cases. If you're not sure of the path to the build documentation, run: % nox --session clone docs See Running the project locally for more information on kicking off the build process on your machine. Example noxfile.py modifications Here are some diffs to illustrate typical modifications made to the default noxfile.py : Arviz Nox Polars PyMC Invoke Add GH_TOKEN as a repository secret How to create a GitHub token Under your profile. Go to Settings . Select Developer settings Select Tokens . Finally, select the scoped of your token. Cookiecutter dash docset needs a GitHub token to create commits and pull requests on our behalf. Create a GitHub token with the following scopes: repo repo:status repo_deployment public_repo repo:invite security_events workflow admin:org write:org read:org manage_runners:org How to add a GitHub repository secret On your GitHub repository, go to the Settings Under Secrets , select Actions . Create a repository secret by clicking New repository secret . Paste your token and name it GH_TOKEN . Add this token as a GitHub repository secret named GH_TOKEN . Install additional dependencies in .github/workflows/build_docs.yml Note This step is only needed if building the documentation requires dependencies that cannot be pip installed by nox . If there are additional non-python dependencies needed to build the docs add the installation steps in .github/actions/build_docs.yml . .github/workflows/build_docs.yml - name : Setup Nox id : setup-nox uses : wntrblm/nox@2022.8.7 with : python-versions : \"{{ cookiecutter.python_version }}\" { # (1) #} - name : Build docs id : build-docs env : { % raw -% } GITHUB_TOKEN : $ {{ secrets.GITHUB_TOKEN }} { % - endraw % } run : | nox --tags build Here we could install extra dependencies needed to build the docs. For example, if we need pandoc, we can install it via the r-lib/actions/setup-pandoc@v2 action. - name : Setup pandoc id : setup-pandoc uses : r-lib/actions/setup-pandoc@v2 with : pandoc-version : \"2.17.1\" Examples of additional dependencies When building the docset for Polars we install Rust before we start the Build docs step .","title":"Modifying the project"},{"location":"modifying_the_project/#modifying-the-project","text":"","title":"Modifying the project"},{"location":"modifying_the_project/#modifying-the-templates-noxfilepy","text":"What's a noxfile and what's nox ? nox is a command line tool for automating the building of environments and running actions. Cookiecutter dash docset uses it to install the dependencies needed to build the documentation and run the build commands. There are 2\u20133 methods you will use: Session.install runs pip commands in the environment created by nox . So if creating your doc-building environment requires you to run: % pip install . % pip install --requirement = docs/requirements.txt This would translate to: session . install ( \".\" ) session . install ( \"--requirement=docs/requirements.txt\" ) Session.chdir Changes the current working directory. Session.run Runs a command in the environment created by nox . If building your docs requires you to run: % cd docs % make html We'll use Session.chdir to translate this to: with session . chdir ( \"docs\" ): session . run ( \"make\" , \"html\" ) A few modifications will need to be made to the template in ./noxfile.py . First, specify the build steps for the library's documentation by modifying docs . Warning All of the functions you need to modify in noxfile.py \u2014 docs , icon , and dash \u2014are set to raise NotImplimented errors as a reminder to the user to make some changes. This will cause nox to fail by default. Remove them once you have completed your changes. ./noxfile.py @nox . session ( python = PYTHON , tags = [ \"build\" ]) def docs ( session : Session ) -> None : \"\"\"Build {{ cookiecutter.library_name }}'s docs.\"\"\" # Remove the NotImplemented error once the correct doc build steps # have been added raise NotImplementedError ( \"Replace starter code below with correct docs build steps.\" ) { #- (1) #} # Instructions are usually found in a file named CONTRIBUTING.md, # or by copying the steps in the workflows found in # .github/workflows/ # Check if it works by running nox --tags=build in your terminal # This is an example doc step process that works with most libraries # It may or may not work with the library you are targeting with session . chdir ( LIBRARY_REPOSITORY ): session . install ( \".\" ) { #- (2) #} with session . chdir ( pathlib . Path ( LIBRARY_REPOSITORY ) / \"docs\" ): session . install ( \"--requirement=requirements.txt\" ) { #- (3) #} session . run ( \"make\" , \"docs\" , external = True ) { #- (4) #} This line is here to make sure you modify the code below to build the docs for your specific library. Remove it after you're done. Here you typically install the package locally Here you install the extra requirements needed to build the docs themselves\u2014maybe sphinx, mkdocs, etc Finally you run the command that builds the docs Second, specify the correct path to an icon relative to the library's repository root. ./noxfile.py @nox . session ( python = False , tags = [ \"build\" ]) def icon ( session : Session ) -> None : \"\"\"Create dash icon.\"\"\" for size , file_name in (( \"16x16\" , \"icon.png\" ), ( \"32x32\" , \"icon@2x.png\" )): # Using convert instead of magick since only the former is # available by default right now in ubuntu-latest # Remove the NotImplementedError once the correct icon path has # been added { #- (1) #} raise NotImplementedError ( \"Specify the correct path to the icon\" ) session . run ( \"convert\" , # Specify the correct path in the line below \"{{ cookiecutter.library_repository_name }}/path/to/icon.png\" , { #- (2) #} \"-resize\" , size , \"-background\" , \"none\" , \"-gravity\" , \"center\" , \"-extent\" , size , file_name , external = True , ) This line is here to make sure you modify the path below to point to the icon for your library. Remove it after you're done. Replace this line with a path pointing towards an image that can be used as the icon for your documentation. The path should start from the name of the directory containing the repository. When you generate the project using [cookiecutter], {{ cookiecutter.library_repository_name }} will automatically be replaced by the repository directory name. Third, specify the correct path to the build documentation. Most Python libraries will build to library_name/doc/_build/html or library_name/docs/_build/html , so not much\u2014if anything\u2014will need to be changed. But there are some exceptions. If you're not sure where the build documentation will be located, run: % nox --sessions clone docs See Running the project locally for more information on how to run this project on your machine. ./noxfile.py @nox . session ( python = PYTHON , tags = [ \"build\" ]) def dash ( session : Session ) -> None : \"\"\"Create dash docset.\"\"\" session . install ( \"doc2dash\" , CONSTRAINTS_ARG ) # Remove the NotImplementedError once the correct path to the build # documentation has been added { #- (1) #} raise NotImplementedError ( \"Specity the correct path to the build documentation\" ) session . run ( \"doc2dash\" , \"--index-page=index.html\" , \"--icon=icon.png\" , \"--online-redirect-url={{ cookiecutter.documentation_url }}\" , # Replace the path below with the correct path to the # documentation # For python libraries, most of the time the below will work as # is # You may run `nox --sessions clone docs` to observe where the # build docs end up f \" { LIBRARY_REPOSITORY } /docs/_build/html\" , { #- (2) #} * session . posargs , ) # As of 3.0.0, doc2dash does not support 2x icons # See https://github.com/hynek/doc2dash/issues/130 docset_path = _get_docset_path () shutil . copy ( \"icon@2x.png\" , os . fsdecode ( docset_path )) The NotImplimentedError line is here to make sure you modify the path below. Remove it after you're done. If necessary, replace this with the path to the build documentation. The placeholder value will work for most cases. If you're not sure of the path to the build documentation, run: % nox --session clone docs See Running the project locally for more information on kicking off the build process on your machine. Example noxfile.py modifications Here are some diffs to illustrate typical modifications made to the default noxfile.py : Arviz Nox Polars PyMC Invoke","title":"Modifying the template's noxfile.py"},{"location":"modifying_the_project/#add-gh_token-as-a-repository-secret","text":"How to create a GitHub token Under your profile. Go to Settings . Select Developer settings Select Tokens . Finally, select the scoped of your token. Cookiecutter dash docset needs a GitHub token to create commits and pull requests on our behalf. Create a GitHub token with the following scopes: repo repo:status repo_deployment public_repo repo:invite security_events workflow admin:org write:org read:org manage_runners:org How to add a GitHub repository secret On your GitHub repository, go to the Settings Under Secrets , select Actions . Create a repository secret by clicking New repository secret . Paste your token and name it GH_TOKEN . Add this token as a GitHub repository secret named GH_TOKEN .","title":"Add GH_TOKEN as a repository secret"},{"location":"modifying_the_project/#install-additional-dependencies-in-githubworkflowsbuild_docsyml","text":"Note This step is only needed if building the documentation requires dependencies that cannot be pip installed by nox . If there are additional non-python dependencies needed to build the docs add the installation steps in .github/actions/build_docs.yml . .github/workflows/build_docs.yml - name : Setup Nox id : setup-nox uses : wntrblm/nox@2022.8.7 with : python-versions : \"{{ cookiecutter.python_version }}\" { # (1) #} - name : Build docs id : build-docs env : { % raw -% } GITHUB_TOKEN : $ {{ secrets.GITHUB_TOKEN }} { % - endraw % } run : | nox --tags build Here we could install extra dependencies needed to build the docs. For example, if we need pandoc, we can install it via the r-lib/actions/setup-pandoc@v2 action. - name : Setup pandoc id : setup-pandoc uses : r-lib/actions/setup-pandoc@v2 with : pandoc-version : \"2.17.1\" Examples of additional dependencies When building the docset for Polars we install Rust before we start the Build docs step .","title":"Install additional dependencies in .github/workflows/build_docs.yml"},{"location":"running_the_project_locally/","text":"Running the project locally Dependencies If you plan on running this project only through GitHub actions, nothing needs to be installed. If you want to run the project locally, the following need to be installed: git GitHub CLI ( gh ) GNU Make GNU Tar ImageMagick Nox Python Running the project If the needed depdendencies are installed, you can run % nox --tags = build to build the docset locally. and % nox --tags = contribute To contribute the built docset. These are the exact commands that are ran on GitHub actions.","title":"Running the project locally"},{"location":"running_the_project_locally/#running-the-project-locally","text":"","title":"Running the project locally"},{"location":"running_the_project_locally/#dependencies","text":"If you plan on running this project only through GitHub actions, nothing needs to be installed. If you want to run the project locally, the following need to be installed: git GitHub CLI ( gh ) GNU Make GNU Tar ImageMagick Nox Python","title":"Dependencies"},{"location":"running_the_project_locally/#running-the-project","text":"If the needed depdendencies are installed, you can run % nox --tags = build to build the docset locally. and % nox --tags = contribute To contribute the built docset. These are the exact commands that are ran on GitHub actions.","title":"Running the project"}]}